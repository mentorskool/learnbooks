{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of aws_s3.ipynb","provenance":[{"file_id":"1x4sRlXi8nF1Vz5nNljadSlzwX-vCed70","timestamp":1630421205462},{"file_id":"1vcVEOpHakhCBRloIV2bpr_uni9btkO44","timestamp":1625971799420}],"collapsed_sections":["ELoPctxHkqC1","VYuJbpY6sN0C","rF5qGPyY_QcG","ZQUErYEqntLq","kvbs5aMhjcvM","XfyVb4EQlD3F","EEKNIM69mhkn","renYPlEonkSs","ktkAzbiFwuxl","Ew7OVgWwdf3S","vuf8oUKHeYdH"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"58AOQ44keVhz"},"source":["# **AWS Storage Service - Simple Storage Service (S3)**"]},{"cell_type":"markdown","metadata":{"id":"fIVC5ySy679j"},"source":["## **Learning Outcomes**\n","\n","\n","---\n","*After going through this notebook, the student should be able to explain*\n","\n","\n","1.   *An overview of simple storage service(S3).*\n","2.   *Criterias to create a DNS compliant bucket name.*\n","1.   *Various bucket permissions like ACL and bucket policy.*\n","2.   *How to work with various properties (versioning, static website hosting,etc.,) of a bucket using AWS console.*\n","1.   *what are the various storage classes (S3-standard, standard-IA,etc.,) available for the users.*\n","2.   *The concept of cross regional replication.*\n","\n","\n","---\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ELoPctxHkqC1"},"source":["### **S3 Overview**\n","\n","\n","---\n","After several discussions between you and your architect and product engineer, team decided to build a **datalake** on **AWS** and so you as a data engineer  evaluated and understood that AWS suits best by considering following **capabilities**\n","\n","\n","  * S3 is AWS object storage service. The objects are stored in a bucket. Here, the bucket is the **container** and the object is the **entity**.\n","\n","  * The **service** is at **regional level**. Hence, makes **copies** of objects at various **availability zone** within the region. This makes the storage durable.\n","\n","  * The bucket can hold as many objects as you want (infinite) but the object size cannot exceed **5 TB**.\n","\n","  * In a free tier account 5 GB of storage is free per month.\n","\n","  * For any account we can create upto **100 buckets**\n","\n","  * **S3 API** calls can be made directly from **AWS console** or using **SDK** from a programmatic languages or even **CLI** from a terminal\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VYuJbpY6sN0C"},"source":["### **DNS Compliant Bucket Name**\n","\n","\n","---\n","\n","\n","*   Unique\n","\n","*   Lowercase\n","\n","*   Alphanumeric\n","\n","*   Special characters (- & .) in the middle of the names.\n","\n","*   length - between 3 to 63 characters.\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6rWcDKz05uco"},"source":["### **Bucket creation**\n","\n","\n","---\n","\n","\n","\n","*   When a bucket is created, the **default permission** is that all the **requests** are **blocked** for anyone on **public** to this bucket. This has to be remembered and changes need to be done to provide access.\n","\n","*   After changes when objects are put into the bucket, they can be accesible to public. Changes to permission can be done with **ACL** or **Bucket Policy**\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hgju0Ph0G-hL"},"source":["<font size=\"3\" color=\"red\"><b>This notebook discusses on how to work with S3 from AWS console </font></b>"]},{"cell_type":"markdown","metadata":{"id":"hznlUCsqnV7R"},"source":["## **S3 from Console**"]},{"cell_type":"markdown","metadata":{"id":"7hNti27LnhUo"},"source":["### **Permissions**"]},{"cell_type":"markdown","metadata":{"id":"rF5qGPyY_QcG"},"source":["#### **Bucket Permissions**\n","\n","\n","---\n","\n","\n","*   **Access control list** - can control access to the bucket, share the bucket with other account, can set bucket for public access, enable sever request logging.\n","\n","*   **Bucket policy** - JSON documents that control the action on the objects within the bucket.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"toWKr4F8noLi"},"source":["### **Properties**"]},{"cell_type":"markdown","metadata":{"id":"ZQUErYEqntLq"},"source":["#### **Versioning**\n","\n","\n","---\n","\n","\n","* Versioning is **disabled** by **default**. It can be enabled but **once** it is **enabled**, it can only be **uspended** (not disabled).\n","\n","* Versioning keeps **track** of various version of the **object**.\n","\n","* Good thing about versioning is that we can **retrive any version** of the object.\n","\n","* But each version will take its own space. so, causing the cost to go up.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kvbs5aMhjcvM"},"source":["#### **Static Webpage Hosting**\n","\n","\n","---\n","\n","\n","* We can specify an index document and error document. For ex., index document as index.html and error document as error.html\n","\n","* Then we can upload the documents into the bucket.\n","\n","* Then make the objects public.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XfyVb4EQlD3F"},"source":["#### **Encryption**\n","\n","\n","---\n","\n","\n","* We have two types of encryption **- AES-256** and **AWS-KMS**. \n","\n","* The former is used to encrypt data at **rest** and the keys are **managed by AWS**. In the **latter**, the keys are created and **managed by the user**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EEKNIM69mhkn"},"source":["#### **Tags**\n","\n","\n","---\n","\n","\n","* Tags are **key value pairs** used for documentation and billing purposes.\n","\n","* For ex., if the resources belonging to a particular projects are tagged, then we can check the billing for that particular project resources in the billing service.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"renYPlEonkSs"},"source":["#### **Transfer Acceleration**\n","\n","\n","---\n","\n","\n","* uses the **edge location** to increase the upload speed to the S3 bucket.\n","\n","* For ex., if the bucket is hosted in mumbai region and the users from other regions like europe, middle east are uploading GB's of data into the bucket it takes time. To acclerate the upload process, the Transfer Acceleration will use the edge location to find the shortest possible route to upload the data.\n","\n","* It can increase the transfer speed upto **300%**\n","\n","* It is not a free service.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0TbCKTuvwqzo"},"source":["### **Management**"]},{"cell_type":"markdown","metadata":{"id":"ktkAzbiFwuxl"},"source":["#### **Storage Classes**\n","\n","\n","---\n","\n","\n","\n","\n","\n","**S3 Standard**\n","\n","\n","---\n","\n","\n","*   Highly available\n","\n","*   Hightly Durable\n","\n","*   Easy and fast access to data\n","\n","*   Can access data frequently\n","\n","**S3 standard-IA**\n","\n","\n","---\n","\n","same as S3 standard but with some changes\n","\n","* minimum object size is 128 KB\n","\n","* data has to be in standard for 30 days before converting it into standard-IA\n","\n","* There is a retrival fee for every GB of data.\n","\n","* Uses include data which needs to be accessed infrequently. eg., archival data\n","\n","**Intelligent-tiering**\n","\n","\n","---\n","\n","\n","* Data labeled as frequent access is automatically converted to IA if not accessed for 30 days.so, resulting in cost saving.\n","\n","* Can be used where it is not possible to anticipate the frequency of data retrival\n","\n","**One zone IA**\n","\n","\n","---\n","\n","\n","* storage and redundant only in one AZ.\n","\n","* used for secondary backups (backup of backup), non-critical data.\n","\n","**Glacier**\n","\n","\n","---\n","\n","\n","* Cheapest storage option but retrival time takes hours.\n","\n","* For eg., you can store compliance data, which we won't access for months or even years.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ew7OVgWwdf3S"},"source":["#### **Lifecycle Management**\n","\n","\n","---\n","\n","* Lifecycle of current and previous versions of the object are configured here.\n","This helps in reducing the storage cost and easy management of objects in the bucket. **Eg:** When you configure Lifecycle management rules, objects are moved from one storage tier to other on a timeframe/ periodically and ultimately deleted which will result in cost saving"]},{"cell_type":"markdown","metadata":{"id":"vuf8oUKHeYdH"},"source":["#### **Cross Region Replication**\n","\n","\n","---\n","\n","* Two buckets in different regions are linked, in which the destination bucket will contain the copy of the objects newly added to the source bucket.\n","\n","\n","* For this to happen Versioning has to be enabled in both the buckets.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OTSac468fwW5"},"source":["## **Reference**\n","\n","**<font size=\"3\" color=\"green\"><b>Special Thanks to Rohan Aurora for creating this beatiful resource</font></b>**\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"cellView":"form","id":"qwhUBKxILa-K","executionInfo":{"status":"ok","timestamp":1625631356604,"user_tz":-330,"elapsed":367,"user":{"displayName":"somanadha sastry Konduri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiaUZN668FhncVQbNTbUc4cwGajKEzvRVKOxuNodw=s64","userId":"17809800069131820864"}},"outputId":"9e42463f-d13d-45c6-d6c9-191d872a40f7"},"source":["#@markdown **1. Video on EC2**\n","from IPython.display import YouTubeVideo\n","YouTubeVideo('q5kSzwx7x1U&ab',width=900, height=500)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <iframe\n","            width=\"900\"\n","            height=\"500\"\n","            src=\"https://www.youtube.com/embed/q5kSzwx7x1U&ab\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.YouTubeVideo at 0x7f765541f590>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"0YPx7fUqNTmA"},"source":["## **Its Practise Time..**"]},{"cell_type":"markdown","metadata":{"id":"iOyB-HmMNXfV"},"source":["**Answer the following questions**\n","\n","\n","---\n","\n","\n","\n","1. If versioning was enabled for your S3 bucket, how will you be billed for the following scenario:                                              At the start of the month you have 3.2 GB (3,294,967,296 bytes), and on the start of the 13th-day of the month the same file was overwritten, leading to the file size of 7.3 GB (7,368,709,120 bytes). Assume there are 31 days in the said month. Choose the right answer considering it as a free tier account and the S3 bucket is in the Mumbai region and it is standard storage?\n","\n","\n","---\n","\n","\n","2. What is the significance of durability in an S3 storage class and what is the durability of  S3 one zone-IA?\n","\n","---\n","\n","3. When to use ACL and When to use Bucket Policy?\n","\n","---\n","\n","4. What is the best way to upload a 20GB file onto S3?\n","\n","---\n","\n","5. What is a good option to improve S3 performance when we have a high number of GET requests?\n","\n","---\n","\n","6. Santhosh is teaching, how to generate data using Kinesis streams. He wants to store this data in S3.  He requires the last 30 days of data to do Big data Analysis. Data prior to 30 days is stored as back up, such that, he can share them with any of his students on their request (Although he feels that this is not mission-critical and won't bother if he loses data). Data older than one year has to be deleted. Can you please provide a solution such that he can reduce his monthly bill? \n","\n","---\n","\n","7. Santhosh who is located in India wants to do big data analysis on Databricks. Since the Databricks he is using is a community edition it is only available in us-west-2. Amit wants this data to be stored in AWS S3 for ease of availability and access. But he needs a suggestion in which region the bucket should be created. As a data engineer what would you suggest and why?\n","\n","---\n","\n","8. Santhosh wants to develop an application such that, it uploads images, store images in location, meta-data of that image in another location. As a data professional what would you suggest?"]}]}